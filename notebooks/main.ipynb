{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os \n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "ROOT = os.path.abspath('../')\n",
    "sys.path.append(ROOT)\n",
    "\n",
    "from imagenet.imagenet_train import train\n",
    "from imagenet.visualize import visualize_model\n",
    "from imagenet.inference import ImageClassification\n",
    "from ocr_tools.craft_ocr.test import start_craft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "   description='Text Reader')\n",
    "\n",
    "parser.add_argument('command',\n",
    "                metavar='<command>',\n",
    "                help=\"'train, detect, evaluate'\")\n",
    "\n",
    "\n",
    "parser.add_argument('--device')\n",
    "parser.add_argument('--network')\n",
    "parser.add_argument('--weights')\n",
    "parser.add_argument('--save_weights')\n",
    "parser.add_argument('--folder_path')\n",
    "\n",
    "parser.add_argument('--trained_model', default=os.path.join(ROOT, 'ocr_tools/craft_ocr/weights/craft_mlt_25k.pth'), type=str, help='pretrained model')\n",
    "parser.add_argument('--text_threshold', default=0.7, type=float, help='text confidence threshold')\n",
    "parser.add_argument('--low_text', default=0.4, type=float, help='text low-bound score')\n",
    "parser.add_argument('--link_threshold', default=0.4, type=float, help='link confidence threshold')\n",
    "parser.add_argument('--cuda', default=False, help='Use cuda for inference')\n",
    "parser.add_argument('--canvas_size', default=1280, type=int, help='image size for inference')\n",
    "parser.add_argument('--mag_ratio', default=1.5, type=float, help='image magnification ratio')\n",
    "parser.add_argument('--poly', default=False, action='store_true', help='enable polygon type')\n",
    "parser.add_argument('--show_time', default=False, action='store_true', help='show processing time')\n",
    "parser.add_argument('--test_folder', default='/data/', type=str, help='folder path to input images')\n",
    "parser.add_argument('--refine', default=False, action='store_true', help='enable link refiner')\n",
    "parser.add_argument('--refiner_model', default='weights/craft_refiner_CTW1500.pth', type=str,\n",
    "                    help='pretrained refiner model')\n",
    "parser.add_argument('--image_folder', default='lol', help='path to image_folder which contains text images')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=4)\n",
    "parser.add_argument('--batch_size', type=int, default=192, help='input batch size')\n",
    "parser.add_argument('--saved_model', help=\"path to saved_model to evaluation\",\n",
    "                    default=os.path.join(ROOT,'ocr_tools/craft_ocr/weights/TPS-ResNet-BiLSTM-Attn.pth'))\n",
    "\n",
    "parser.add_argument('--batch_max_length', type=int, default=25, help='maximum-label-length')\n",
    "parser.add_argument('--imgH', type=int, default=32, help='the height of the input image')\n",
    "parser.add_argument('--imgW', type=int, default=100, help='the width of the input image')\n",
    "parser.add_argument('--rgb', action='store_true', help='use rgb input')\n",
    "parser.add_argument('--character', type=str, default='0123456789abcdefghijklmnopqrstuvwxyz', help='character label')\n",
    "parser.add_argument('--sensitive', action='store_true', help='for sensitive character mode')\n",
    "parser.add_argument('--PAD', action='store_true', help='whether to keep ratio then pad for image resize')\n",
    "\n",
    "parser.add_argument('--Transformation', type=str, help='Transformation stage. None|TPS', default='TPS')\n",
    "parser.add_argument('--FeatureExtraction', type=str, help='FeatureExtraction stage. VGG|RCNN|ResNet',\n",
    "                    default='ResNet')\n",
    "parser.add_argument('--SequenceModeling', type=str, help='SequenceModeling stage. None|BiLSTM', default='BiLSTM')\n",
    "parser.add_argument('--Prediction', type=str, help='Prediction stage. CTC|Attn', default='Attn')\n",
    "parser.add_argument('--num_fiducial', type=int, default=20, help='number of fiducial points of TPS-STN')\n",
    "parser.add_argument('--input_channel', type=int, default=1, help='the number of input channel of Feature extractor')\n",
    "parser.add_argument('--output_channel', type=int, default=512,\n",
    "                    help='the number of output channel of Feature extractor')\n",
    "parser.add_argument('--hidden_size', type=int, default=256, help='the size of the LSTM hidden state')\n",
    "\n",
    "args = parser.parse_args(\"process \\\n",
    "       --folder_path={0}/imagenet/data/test  \\\n",
    "       --device=cpu \\\n",
    "       --weights={0}/imagenet/weights/model_final.pth \\\n",
    "       --test_folder={0}/imagenet/data/test\".format(ROOT).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/217.jpg\n",
      "box /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/216.jpg\n",
      "size /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/288.jpg\n",
      "size /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/289.jpg\n",
      "size /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/298.jpg\n",
      "size /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/294.jpg\n",
      "Load Mask RCNN\n",
      "Loading weights from checkpoint (/Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/ocr_tools/craft_ocr/weights/craft_mlt_25k.pth)\n",
      "Process Mask RCNN and cropp imagesments/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/box/217.jpg\n",
      "4 [ 32.566307 425.85513  648.5377   688.91785 ]\n",
      "Reading barcodes\n",
      "[Decoded(data=b'0889136953660', type='EAN13', rect=Rect(left=432, top=70, width=175, height=119), polygon=[Point(x=432, y=173), Point(x=432, y=189), Point(x=603, y=188), Point(x=604, y=172), Point(x=606, y=110), Point(x=607, y=74), Point(x=607, y=70), Point(x=434, y=71), Point(x=433, y=103)])]\n",
      "[INFO] Found EAN13 barcode: 0889136953660\n",
      "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
      "loading pretrained model from /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/ocr_tools/craft_ocr/weights/TPS-ResNet-BiLSTM-Attn.pth\n",
      "['bb2886', 'nmd', 'r1', 'obbitighted', 'reant', 'is', '10', 'f', 'uk', '8', '89136', '95366', '44', '91', 'originals', 'originals', 'upc', 'pow', '116248250', 'compatible', 'made', 'invietnam', 'fabriquenumitian', 'abseonusionanci']\n",
      "Process Mask RCNN and cropp imagesments/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/box/216.jpg\n",
      "4 [339.75262 456.49493 628.06354 576.9213 ]\n",
      "Reading barcodes\n",
      "[]\n",
      "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
      "loading pretrained model from /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/ocr_tools/craft_ocr/weights/TPS-ResNet-BiLSTM-Attn.pth\n",
      "['s77417', 'boost', 'm', 'ultra', 'us', '101', '10', '441', 'runnoccouse', 'running']\n",
      "Process Mask RCNN and cropp imagesments/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/size/288.jpg\n",
      "4 [216.16432 268.8581  546.5286  560.94556]\n",
      "Reading barcodes\n",
      "[]\n",
      "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
      "loading pretrained model from /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/ocr_tools/craft_ocr/weights/TPS-ResNet-BiLSTM-Attn.pth\n",
      "['made', 'in', 'vietnam', 'fr', 'uk', 'jpchn', 'us', '285', '295', '46', '11', '11x', 'maleimale', '06416', '875001', 'shw', 'artbbig67', '14809846', 'in', 'i', 'h1', 'das', '3datzlife0028']\n",
      "Process Mask RCNN and cropp imagesments/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/size/289.jpg\n",
      "4 [239.42186 226.96591 503.15485 481.96066]\n",
      "Reading barcodes\n",
      "[]\n",
      "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
      "loading pretrained model from /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/ocr_tools/craft_ocr/weights/TPS-ResNet-BiLSTM-Attn.pth\n",
      "['made', 'in', 'china', 'uk', 'fr', 'us', 'jpchn', '10x', '10', '4436', '285', '275', 'maleimale', 'yya', '606001', '10m15', 'arts77417', 'the', 'h113624203', 'adidas', 'viapozot0126']\n",
      "Process Mask RCNN and cropp imagesments/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/size/298.jpg\n",
      "4 [157.91418 176.69037 445.49023 437.34613]\n",
      "Reading barcodes\n",
      "[]\n",
      "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
      "loading pretrained model from /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/ocr_tools/craft_ocr/weights/TPS-ResNet-BiLSTM-Attn.pth\n",
      "['in', 'made', 'china', 'uk', 'fr', 'jpochn', 'us', '9x', '9', '43x', '275', '265', 'maleimale', 'only', 'clu', '07h13', '600001', 'art', 'q33087', '41', '08147225', 'adidas', 'dkofdyzdo6002']\n",
      "Process Mask RCNN and cropp imagesments/Business/Projects/Upwork/SportLabels/code/imagenet/data/test/size/294.jpg\n",
      "4 [155.50227 283.01303 531.2868  457.34653]\n",
      "Reading barcodes\n",
      "[]\n",
      "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
      "loading pretrained model from /Users/dmitry/Documents/Business/Projects/Upwork/SportLabels/code/ocr_tools/craft_ocr/weights/TPS-ResNet-BiLSTM-Attn.pth\n",
      "['poping', 'restating', 'this', 'soc', 'lv', 'al', 'a']\n",
      "elapsed time : 67.96802997589111s\n"
     ]
    }
   ],
   "source": [
    "im = ImageClassification(args.folder_path)\n",
    "im.start(args.device, args.weights)\n",
    "start_craft(args, ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
